# -*- coding: utf-8 -*-
"""app4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19C3wxi8XYIbkRdVFpjbuHZ9V3vjNfx0V
"""

import streamlit as st
from transformers import pipeline

def answer_question(corpus_text, question_text, model_name="deepset/roberta-base-squad2"):
  """
  Answers a question using a pre-trained question answering model.

  Args:
      corpus_text (str): The text passage to answer the question about.
      question_text (str): The question to be answered.
      model_name (str, optional): The name of the pre-trained question answering model. Defaults to "deepset/roberta-base-squad2".

  Returns:
      str: The answer extracted from the corpus text based on the question.
  """

  # Load the question answering pipeline
  nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)

  # Prepare the input for the model
  QA_input = {
      'question': question_text,
      'context': corpus_text
  }

  # Get the answer using the pipeline
  res = nlp(QA_input)

  return res['answer']

def main():
  """
  Builds the Streamlit application for the question answering system.
  """

  st.title("AI-Powered Question Answering")  # Clear and descriptive title

  # Text input fields with placeholders for better guidance
  corpus_text = st.text_area("Enter the text you want to analyze (corpus):", height=200)
  question_text = st.text_input("Ask your question:", placeholder="What would you like to know?")

  # Button to trigger the question answering process
  if st.button("Answer My Question"):
    if corpus_text and question_text:
      answer = answer_question(corpus_text, question_text)
      st.success("**Answer:** {}".format(answer))  # Success message with formatting
    else:
      st.warning("Please provide both corpus text and a question.")

if __name__ == "__main__":
  main()